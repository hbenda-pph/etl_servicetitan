# ETL ServiceTitan - BigQuery

Sistema ETL completo para extraer datos de ServiceTitan API y cargarlos a BigQuery con campos de auditor√≠a y Soft Delete.

## üèóÔ∏è Arquitectura

```
Cloud Function (orchestrate-etl-jobs)
    ‚Üì Invoca secuencialmente
Cloud Run Job #1 (etl-st2json-job) 
    ‚Üì Extrae datos de ServiceTitan API ‚Üí JSON
Cloud Run Job #2 (etl-json2bq-job)
    ‚Üì Procesa JSON ‚Üí BigQuery con campos ETL
```

## üìã Componentes

### 1. **Cloud Function (Orquestador)**
- **Nombre**: `orchestrate-etl-jobs`
- **Funci√≥n**: Coordina la ejecuci√≥n secuencial de ambos Jobs
- **Timeout**: 3600s (1 hora)
- **Memoria**: 4Gi
- **Regi√≥n**: us-east1

### 2. **Cloud Run Job #1 (Extracci√≥n)**
- **Nombre**: `etl-st2json-job`
- **Funci√≥n**: Extrae datos de ServiceTitan API y los convierte a JSON
- **Timeout**: 7200s (2 horas)
- **Memoria**: 1Gi
- **CPU**: 2 cores
- **Tiempo t√≠pico**: 7-18 minutos

### 3. **Cloud Run Job #2 (Procesamiento)**
- **Nombre**: `etl-json2bq-job`
- **Funci√≥n**: Procesa archivos JSON y los carga a BigQuery con campos ETL
- **Timeout**: 7200s (2 horas)
- **Memoria**: 1Gi
- **CPU**: 2 cores
- **Tiempo t√≠pico**: 23 minutos m√°ximo

## üîß Campos ETL Implementados

Todas las tablas incluyen campos de auditor√≠a autom√°ticos:

| Campo | Tipo | Prop√≥sito |
|-------|------|-----------|
| `_etl_synced` | TIMESTAMP | Timestamp de la √∫ltima operaci√≥n |
| `_etl_operation` | STRING | Tipo de operaci√≥n: INSERT, UPDATE, DELETE |

## üöÄ Build y Deploy

### ‚ö° M√©todo Recomendado: Scripts Automatizados

Cada job tiene su propio script `build_deploy.sh` que maneja autom√°ticamente el build y deploy seg√∫n el ambiente.

#### Job #1 (Extracci√≥n - st2json-job)

```bash
cd st2json-job

# Deploy seg√∫n ambiente activo de gcloud
./build_deploy.sh

# O especificar ambiente expl√≠citamente
./build_deploy.sh des    # Deploy en DES
./build_deploy.sh qua    # Deploy en QUA
./build_deploy.sh pro    # Deploy en PRO
```

#### Job #2 (Procesamiento - json2bq-job)

```bash
cd json2bq-job

# Deploy seg√∫n ambiente activo de gcloud
./build_deploy.sh

# O especificar ambiente expl√≠citamente
./build_deploy.sh des    # Deploy en DES
./build_deploy.sh qua    # Deploy en QUA
./build_deploy.sh pro    # Deploy en PRO
```

### üìù Caracter√≠sticas de los Scripts

- ‚úÖ **Detecci√≥n autom√°tica de ambiente** basada en proyecto activo de gcloud
- ‚úÖ **Validaci√≥n de ambiente** (des/qua/pro)
- ‚úÖ **Configuraci√≥n autom√°tica** de service accounts y recursos seg√∫n ambiente
- ‚úÖ **Build y Deploy en un solo comando**
- ‚úÖ **Mensajes informativos** con comandos √∫tiles post-deploy

### üîÑ Workflow de Deploy Multi-Ambiente

```bash
# 1. Desarrollo (DES)
gcloud config set project platform-partners-des
cd st2json-job && ./build_deploy.sh && cd ..
cd json2bq-job && ./build_deploy.sh && cd ..

# 2. Validaci√≥n (QUA)
gcloud config set project platform-partners-qua
cd st2json-job && ./build_deploy.sh && cd ..
cd json2bq-job && ./build_deploy.sh && cd ..

# 3. Producci√≥n (PRO)
gcloud config set project platform-partners-pro
cd st2json-job && ./build_deploy.sh && cd ..
cd json2bq-job && ./build_deploy.sh && cd ..
```

O especificar ambiente expl√≠citamente:
```bash
cd st2json-job
./build_deploy.sh des  # Desarrollo
./build_deploy.sh qua  # Validaci√≥n
./build_deploy.sh pro  # Producci√≥n
```

### üîß M√©todo Manual (Comandos Individuales)

Si prefieres ejecutar los comandos manualmente:

#### Job #1 - Build & Deploy Manual
```bash
cd st2json-job

# Build
gcloud builds submit --tag gcr.io/platform-partners-des/etl-st2json

# Deploy
gcloud run jobs update etl-st2json-job \
  --image gcr.io/platform-partners-des/etl-st2json \
  --region us-east1 \
  --project platform-partners-des \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 1Gi \
  --cpu 2 \
  --max-retries 1 \
  --task-timeout 1800
```

#### Job #2 - Build & Deploy Manual
```bash
cd json2bq-job

# Build
gcloud builds submit --tag gcr.io/platform-partners-des/etl-json2bq

# Deploy
gcloud run jobs update etl-json2bq-job \
  --image gcr.io/platform-partners-des/etl-json2bq \
  --region us-east1 \
  --project platform-partners-des \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 1Gi \
  --cpu 2 \
  --max-retries 1 \
  --task-timeout 2400
```

### Funci√≥n Orquestadora

#### Deploy (No requiere Build)
```bash
gcloud functions deploy orchestrate-etl-jobs \
  --gen2 \
  --project platform-partners-des \
  --runtime python311 \
  --trigger-http \
  --entry-point orchestrate_etl_jobs \
  --source . \
  --region us-east1 \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 4Gi \
  --timeout 3600s \
  --allow-unauthenticated
```

## üìä Funcionalidades

### ‚úÖ Soft Delete
- Los registros eliminados se marcan con `_etl_operation = 'DELETE'`
- No se borran f√≠sicamente de BigQuery
- Permite auditor√≠a completa y recuperaci√≥n

### ‚úÖ Auditor√≠a Completa
- Tracking de todas las operaciones (INSERT, UPDATE, DELETE)
- Timestamp de cada sincronizaci√≥n
- Trazabilidad completa del proceso ETL

### ‚úÖ Procesamiento Incremental
- MERGE con detecci√≥n autom√°tica de cambios
- Actualizaci√≥n solo de registros modificados
- Eficiencia en el procesamiento

## üîç Endpoints Procesados

- business-units
- job-types
- technicians
- employees
- campaigns
- activities
- timesheets

## üß™ Herramientas de Testing

### Script de Prueba ETL Completo

**`test_etl_single_company.py`** - Prueba el flujo completo (extracci√≥n + carga) para una compa√±√≠a:

```bash
# Editar COMPANY_ID y TEST_ENDPOINTS en el archivo
python test_etl_single_company.py
```

### Notebook Interactivo

**`test_etl_flow.ipynb`** - Versi√≥n visual e interactiva:

```bash
jupyter notebook test_etl_flow.ipynb
```

**Uso:** Ideal para probar nuevos endpoints antes de implementarlos en producci√≥n.

## üìÅ Estructura del Proyecto

```
etl_servicetitan/
‚îú‚îÄ‚îÄ orchestrate_etl/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                              # Funci√≥n orquestadora
‚îú‚îÄ‚îÄ st2json-job/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                           # Configuraci√≥n Docker
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias Python
‚îÇ   ‚îú‚îÄ‚îÄ servicetitan_all_st_to_json.py      # Script principal
‚îÇ   ‚îú‚îÄ‚îÄ estimates_single_company.py          # Script para estimates individual
‚îÇ   ‚îî‚îÄ‚îÄ build_deploy.sh                      # Script de build & deploy
‚îú‚îÄ‚îÄ json2bq-job/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                           # Configuraci√≥n Docker
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias Python
‚îÇ   ‚îú‚îÄ‚îÄ servicetitan_all_json_to_bigquery.py # Script principal
‚îÇ   ‚îî‚îÄ‚îÄ build_deploy.sh                      # Script de build & deploy
‚îú‚îÄ‚îÄ test_etl_single_company.py               # Script de prueba ETL completo
‚îú‚îÄ‚îÄ test_etl_flow.ipynb                       # Notebook de prueba ETL
‚îî‚îÄ‚îÄ README.md                                # Documentaci√≥n completa
```

## üõ†Ô∏è Configuraci√≥n

### Service Account
- **Nombre**: `etl-servicetitan@platform-partners-des.iam.gserviceaccount.com`
- **Permisos**: BigQuery, Cloud Run, Cloud Storage

### Proyectos
- **Orquestaci√≥n**: `platform-partners-des`
- **Datos**: `shape-mhs-1` (cada compa√±√≠a tiene su propio proyecto)

### Permisos para Cloud Functions

#### Verificar Cuenta de Servicio
```bash
gcloud iam service-accounts list --filter="email:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com"
```

#### Verificar Jobs Disponibles
```bash
gcloud run jobs list --region=us-east1
```

#### Configurar Permisos Completos
```bash
# Permisos de administrador de Cloud Run
gcloud projects add-iam-policy-binding platform-partners-des \
  --member="serviceAccount:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com" \
  --role="roles/run.admin"

# Permisos para invocar Jobs
gcloud projects add-iam-policy-binding platform-partners-des \
  --member="serviceAccount:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com" \
  --role="roles/run.invoker"
```

## üîê Configuraci√≥n de Permisos para Jobs INBOX (pph-inbox)

### **Soluci√≥n Todo-en-Uno** (Recomendado)

Si quieres configurar todos los permisos de una vez:

```bash
PROJECT_NUMBER=$(gcloud projects describe pph-inbox --format="value(projectNumber)")
SERVICE_ACCOUNT="${PROJECT_NUMBER}-compute@developer.gserviceaccount.com"

# Habilitar APIs necesarias
gcloud services enable cloudbuild.googleapis.com --project=pph-inbox
gcloud services enable artifactregistry.googleapis.com --project=pph-inbox

# Otorgar todos los roles necesarios
gcloud projects add-iam-policy-binding pph-inbox \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/cloudbuild.builds.builder"

gcloud projects add-iam-policy-binding pph-inbox \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/storage.admin"

gcloud projects add-iam-policy-binding pph-inbox \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/artifactregistry.writer"

gcloud projects add-iam-policy-binding pph-inbox \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/logging.logWriter"

# Otorgar permiso para usar el service account etl-servicetitan (necesario para Cloud Run Jobs)
# Para la cuenta de servicio de compute (usada por Cloud Build)
gcloud iam service-accounts add-iam-policy-binding etl-servicetitan@pph-inbox.iam.gserviceaccount.com \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/iam.serviceAccountUser" \
    --project=pph-inbox

# Para la cuenta de usuario que ejecuta comandos gcloud (reemplaza TU_CUENTA@DOMINIO.com)
gcloud iam service-accounts add-iam-policy-binding etl-servicetitan@pph-inbox.iam.gserviceaccount.com \
    --member="user:TU_CUENTA@DOMINIO.com" \
    --role="roles/iam.serviceAccountUser" \
    --project=pph-inbox
```

### Permisos de BigQuery para el Service Account

El service account `etl-servicetitan@pph-inbox.iam.gserviceaccount.com` necesita permisos en `pph-inbox`:

```bash
gcloud projects add-iam-policy-binding pph-inbox \
    --member="serviceAccount:etl-servicetitan@pph-inbox.iam.gserviceaccount.com" \
    --role="roles/bigquery.admin"
```

## üìà Monitoreo

### Logs de Cloud Run Jobs
```bash
# Job 1 - Extracci√≥n de datos
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=etl-st2json-job" --limit=50 --format="table(timestamp,severity,textPayload)"

# Job 2 - Procesamiento a BigQuery
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=etl-json2bq-job" --limit=50 --format="table(timestamp,severity,textPayload)"
```

### Logs de Cloud Function
```bash
# Funci√≥n de orquestaci√≥n
gcloud logging read "resource.type=cloud_function AND resource.labels.function_name=orchestrate-etl-jobs" --limit=50 --format="table(timestamp,severity,textPayload)"
```

### Monitoreo de BigQuery
- **Dataset**: `shape-mhs-1.management`
- **Tabla de logs**: `etl_logs`
- **Campos ETL**: `_etl_synced`, `_etl_operation`

## üß™ Pruebas y Scheduling

### Pruebas Manuales
```bash
# Probar la funci√≥n de orquestaci√≥n directamente
curl -X POST https://us-east1-platform-partners-des.cloudfunctions.net/orchestrate-etl-jobs
```

### Configuraci√≥n de Scheduler
```bash
# Crear job de scheduler (cada 6 horas)
gcloud scheduler jobs create http etl-orchestration-schedule \
  --schedule="0 */6 * * *" \
  --uri="https://us-east1-platform-partners-des.cloudfunctions.net/orchestrate-etl-jobs" \
  --http-method=POST \
  --location=us-east1 \
  --oidc-service-account-email=etl-servicetitan@platform-partners-des.iam.gserviceaccount.com

# Verificar jobs de scheduler
gcloud scheduler jobs list --location=us-east1

# Ejecutar manualmente el scheduler
gcloud scheduler jobs run etl-orchestration-schedule --location=us-east1

# Verificar estado del scheduler
gcloud scheduler jobs describe etl-orchestration-schedule --location=us-east1
```

## üîß Troubleshooting

### Error de Timeout
- **S√≠ntoma**: "Operation did not complete within the designated timeout"
- **Soluci√≥n**: Verificar que el timeout de la funci√≥n sea mayor que la suma de ambos Jobs

### Campos ETL Faltantes
- **S√≠ntoma**: Tablas sin campos `_etl_synced` o `_etl_operation`
- **Soluci√≥n**: Ejecutar script de migraci√≥n de esquemas

### Jobs No Ejecutados
- **S√≠ntoma**: Funci√≥n termina sin ejecutar Jobs
- **Soluci√≥n**: Verificar permisos del Service Account

## üìù Notas de Desarrollo

- Los campos ETL se agregan autom√°ticamente a nuevas tablas
- El MERGE maneja Soft Delete para registros eliminados
- La orquestaci√≥n es s√≠ncrona (espera a que ambos Jobs terminen)
- Los logs est√°n optimizados para facilitar el monitoreo
