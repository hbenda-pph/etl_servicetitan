# ETL ServiceTitan - BigQuery

Sistema ETL completo para extraer datos de ServiceTitan API y cargarlos a BigQuery con campos de auditorÃ­a y Soft Delete.

## ğŸ—ï¸ Arquitectura

```
Cloud Function (orchestrate-etl-jobs)
    â†“ Invoca secuencialmente
Cloud Run Job #1 (etl-st2json-job) 
    â†“ Extrae datos de ServiceTitan API â†’ JSON
Cloud Run Job #2 (etl-json2bq-job)
    â†“ Procesa JSON â†’ BigQuery con campos ETL
```

## ğŸ“‹ Componentes

### 1. **Cloud Function (Orquestador)**
- **Nombre**: `orchestrate-etl-jobs`
- **FunciÃ³n**: Coordina la ejecuciÃ³n secuencial de ambos Jobs
- **Timeout**: 3600s (1 hora)
- **Memoria**: 4Gi
- **RegiÃ³n**: us-east1

### 2. **Cloud Run Job #1 (ExtracciÃ³n)**
- **Nombre**: `etl-st2json-job`
- **FunciÃ³n**: Extrae datos de ServiceTitan API y los convierte a JSON
- **Timeout**: 7200s (2 horas)
- **Memoria**: 1Gi
- **CPU**: 2 cores
- **Tiempo tÃ­pico**: 7-18 minutos

### 3. **Cloud Run Job #2 (Procesamiento)**
- **Nombre**: `etl-json2bq-job`
- **FunciÃ³n**: Procesa archivos JSON y los carga a BigQuery con campos ETL
- **Timeout**: 7200s (2 horas)
- **Memoria**: 1Gi
- **CPU**: 2 cores
- **Tiempo tÃ­pico**: 23 minutos mÃ¡ximo

## ğŸ”§ Campos ETL Implementados

Todas las tablas incluyen campos de auditorÃ­a automÃ¡ticos:

| Campo | Tipo | PropÃ³sito |
|-------|------|-----------|
| `_etl_synced` | TIMESTAMP | Timestamp de la Ãºltima operaciÃ³n |
| `_etl_operation` | STRING | Tipo de operaciÃ³n: INSERT, UPDATE, DELETE |

## ğŸš€ Comandos de Build y Deploy

### Job #1 (ExtracciÃ³n)

#### Build
```bash
gcloud builds submit --tag gcr.io/platform-partners-des/etl-st2json
```

#### Deploy
```bash
gcloud run jobs update etl-st2json-job \
  --image gcr.io/platform-partners-des/etl-st2json \
  --region us-east1 \
  --project platform-partners-des \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 1Gi \
  --cpu 2 \
  --max-retries 1 \
  --task-timeout 1800
```

### Job #2 (Procesamiento)

#### Build
```bash
gcloud builds submit --tag gcr.io/platform-partners-des/etl-json2bq
```

#### Deploy
```bash
gcloud run jobs update etl-json2bq-job \
  --image gcr.io/platform-partners-des/etl-json2bq \
  --region us-east1 \
  --project platform-partners-des \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 1Gi \
  --cpu 2 \
  --max-retries 1 \
  --task-timeout 2400
```

### FunciÃ³n Orquestadora

#### Deploy (No requiere Build)
```bash
gcloud functions deploy orchestrate-etl-jobs \
  --gen2 \
  --project platform-partners-des \
  --runtime python311 \
  --trigger-http \
  --entry-point orchestrate_etl_jobs \
  --source . \
  --region us-east1 \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 4Gi \
  --timeout 3600s \
  --allow-unauthenticated
```

## ğŸ“Š Funcionalidades

### âœ… Soft Delete
- Los registros eliminados se marcan con `_etl_operation = 'DELETE'`
- No se borran fÃ­sicamente de BigQuery
- Permite auditorÃ­a completa y recuperaciÃ³n

### âœ… AuditorÃ­a Completa
- Tracking de todas las operaciones (INSERT, UPDATE, DELETE)
- Timestamp de cada sincronizaciÃ³n
- Trazabilidad completa del proceso ETL

### âœ… Procesamiento Incremental
- MERGE con detecciÃ³n automÃ¡tica de cambios
- ActualizaciÃ³n solo de registros modificados
- Eficiencia en el procesamiento

## ğŸ” Endpoints Procesados

- business-units
- job-types
- technicians
- employees
- campaigns
- activities
- timesheets

## ğŸ“ Estructura del Proyecto

```
etl_servicetitan/
â”œâ”€â”€ orchestrate_etl/
â”‚   â””â”€â”€ main.py                 # FunciÃ³n orquestadora
â”œâ”€â”€ st2json-job/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ servicetitan_all_st_to_json.py
â”œâ”€â”€ json2bq-job/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ servicetitan_all_json_to_bigquery.py
â””â”€â”€ README.md
```

## ğŸ› ï¸ ConfiguraciÃ³n

### Service Account
- **Nombre**: `etl-servicetitan@platform-partners-des.iam.gserviceaccount.com`
- **Permisos**: BigQuery, Cloud Run, Cloud Storage

### Proyectos
- **OrquestaciÃ³n**: `platform-partners-des`
- **Datos**: `shape-mhs-1` (cada compaÃ±Ã­a tiene su propio proyecto)

### Permisos para Cloud Functions

#### Verificar Cuenta de Servicio
```bash
gcloud iam service-accounts list --filter="email:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com"
```

#### Verificar Jobs Disponibles
```bash
gcloud run jobs list --region=us-east1
```

#### Configurar Permisos Completos
```bash
# Permisos de administrador de Cloud Run
gcloud projects add-iam-policy-binding platform-partners-des \
  --member="serviceAccount:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com" \
  --role="roles/run.admin"

# Permisos para invocar Jobs
gcloud projects add-iam-policy-binding platform-partners-des \
  --member="serviceAccount:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com" \
  --role="roles/run.invoker"
```

## ğŸ“ˆ Monitoreo

### Logs de Cloud Run Jobs
```bash
# Job 1 - ExtracciÃ³n de datos
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=etl-st2json-job" --limit=50 --format="table(timestamp,severity,textPayload)"

# Job 2 - Procesamiento a BigQuery
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=etl-json2bq-job" --limit=50 --format="table(timestamp,severity,textPayload)"
```

### Logs de Cloud Function
```bash
# FunciÃ³n de orquestaciÃ³n
gcloud logging read "resource.type=cloud_function AND resource.labels.function_name=orchestrate-etl-jobs" --limit=50 --format="table(timestamp,severity,textPayload)"
```

### Monitoreo de BigQuery
- **Dataset**: `shape-mhs-1.management`
- **Tabla de logs**: `etl_logs`
- **Campos ETL**: `_etl_synced`, `_etl_operation`

## ğŸ§ª Pruebas y Scheduling

### Pruebas Manuales
```bash
# Probar la funciÃ³n de orquestaciÃ³n directamente
curl -X POST https://us-east1-platform-partners-des.cloudfunctions.net/orchestrate-etl-jobs
```

### ConfiguraciÃ³n de Scheduler
```bash
# Crear job de scheduler (cada 6 horas)
gcloud scheduler jobs create http etl-orchestration-schedule \
  --schedule="0 */6 * * *" \
  --uri="https://us-east1-platform-partners-des.cloudfunctions.net/orchestrate-etl-jobs" \
  --http-method=POST \
  --location=us-east1 \
  --oidc-service-account-email=etl-servicetitan@platform-partners-des.iam.gserviceaccount.com

# Verificar jobs de scheduler
gcloud scheduler jobs list --location=us-east1

# Ejecutar manualmente el scheduler
gcloud scheduler jobs run etl-orchestration-schedule --location=us-east1

# Verificar estado del scheduler
gcloud scheduler jobs describe etl-orchestration-schedule --location=us-east1
```

## ğŸ”§ Troubleshooting

### Error de Timeout
- **SÃ­ntoma**: "Operation did not complete within the designated timeout"
- **SoluciÃ³n**: Verificar que el timeout de la funciÃ³n sea mayor que la suma de ambos Jobs

### Campos ETL Faltantes
- **SÃ­ntoma**: Tablas sin campos `_etl_synced` o `_etl_operation`
- **SoluciÃ³n**: Ejecutar script de migraciÃ³n de esquemas

### Jobs No Ejecutados
- **SÃ­ntoma**: FunciÃ³n termina sin ejecutar Jobs
- **SoluciÃ³n**: Verificar permisos del Service Account

## ğŸ“ Notas de Desarrollo

- Los campos ETL se agregan automÃ¡ticamente a nuevas tablas
- El MERGE maneja Soft Delete para registros eliminados
- La orquestaciÃ³n es sÃ­ncrona (espera a que ambos Jobs terminen)
- Los logs estÃ¡n optimizados para facilitar el monitoreo
