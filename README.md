# ETL ServiceTitan - BigQuery

Sistema ETL completo para extraer datos de ServiceTitan API y cargarlos a BigQuery con campos de auditorÃ­a y Soft Delete.

## ğŸ—ï¸ Arquitectura

```
Cloud Function (orchestrate-etl-jobs)
    â†“ Invoca secuencialmente
Cloud Run Job #1 (etl-st2json-job) 
    â†“ Extrae datos de ServiceTitan API â†’ JSON
Cloud Run Job #2 (etl-json2bq-job)
    â†“ Procesa JSON â†’ BigQuery con campos ETL
```

## ğŸ“‹ Componentes

### 1. **Cloud Function (Orquestador)**
- **Nombre**: `orchestrate-etl-jobs`
- **FunciÃ³n**: Coordina la ejecuciÃ³n secuencial de ambos Jobs
- **Timeout**: 3600s (1 hora)
- **Memoria**: 4Gi
- **RegiÃ³n**: us-east1

### 2. **Cloud Run Job #1 (ExtracciÃ³n)**
- **Nombre**: `etl-st2json-job`
- **FunciÃ³n**: Extrae datos de ServiceTitan API y los convierte a JSON
- **Timeout**: 7200s (2 horas)
- **Memoria**: 1Gi
- **CPU**: 2 cores
- **Tiempo tÃ­pico**: 7-18 minutos

### 3. **Cloud Run Job #2 (Procesamiento)**
- **Nombre**: `etl-json2bq-job`
- **FunciÃ³n**: Procesa archivos JSON y los carga a BigQuery con campos ETL
- **Timeout**: 7200s (2 horas)
- **Memoria**: 1Gi
- **CPU**: 2 cores
- **Tiempo tÃ­pico**: 23 minutos mÃ¡ximo

## ğŸ”§ Campos ETL Implementados

Todas las tablas incluyen campos de auditorÃ­a automÃ¡ticos:

| Campo | Tipo | PropÃ³sito |
|-------|------|-----------|
| `_etl_synced` | TIMESTAMP | Timestamp de la Ãºltima operaciÃ³n |
| `_etl_operation` | STRING | Tipo de operaciÃ³n: INSERT, UPDATE, DELETE |

## ğŸš€ Build y Deploy

### âš¡ MÃ©todo Recomendado: Scripts Automatizados

Cada job tiene su propio script `build_deploy.sh` que maneja automÃ¡ticamente el build y deploy segÃºn el ambiente.

#### Job #1 (ExtracciÃ³n - st2json-job)

```bash
cd st2json-job

# Deploy segÃºn ambiente activo de gcloud
./build_deploy.sh

# O especificar ambiente explÃ­citamente
./build_deploy.sh des    # Deploy en DES
./build_deploy.sh qua    # Deploy en QUA
./build_deploy.sh pro    # Deploy en PRO
```

#### Job #2 (Procesamiento - json2bq-job)

```bash
cd json2bq-job

# Deploy segÃºn ambiente activo de gcloud
./build_deploy.sh

# O especificar ambiente explÃ­citamente
./build_deploy.sh des    # Deploy en DES
./build_deploy.sh qua    # Deploy en QUA
./build_deploy.sh pro    # Deploy en PRO
```

### ğŸ“ CaracterÃ­sticas de los Scripts

- âœ… **DetecciÃ³n automÃ¡tica de ambiente** basada en proyecto activo de gcloud
- âœ… **ValidaciÃ³n de ambiente** (des/qua/pro)
- âœ… **ConfiguraciÃ³n automÃ¡tica** de service accounts y recursos segÃºn ambiente
- âœ… **Build y Deploy en un solo comando**
- âœ… **Mensajes informativos** con comandos Ãºtiles post-deploy

### ğŸ”„ Workflow de Deploy Multi-Ambiente

```bash
# 1. Desarrollo (DES)
gcloud config set project platform-partners-des
cd st2json-job && ./build_deploy.sh && cd ..
cd json2bq-job && ./build_deploy.sh && cd ..

# 2. ValidaciÃ³n (QUA)
gcloud config set project platform-partners-qua
cd st2json-job && ./build_deploy.sh && cd ..
cd json2bq-job && ./build_deploy.sh && cd ..

# 3. ProducciÃ³n (PRO)
gcloud config set project platform-partners-pro
cd st2json-job && ./build_deploy.sh && cd ..
cd json2bq-job && ./build_deploy.sh && cd ..
```

O especificar ambiente explÃ­citamente:
```bash
cd st2json-job
./build_deploy.sh des  # Desarrollo
./build_deploy.sh qua  # ValidaciÃ³n
./build_deploy.sh pro  # ProducciÃ³n
```

### ğŸ”§ MÃ©todo Manual (Comandos Individuales)

Si prefieres ejecutar los comandos manualmente:

#### Job #1 - Build & Deploy Manual
```bash
cd st2json-job

# Build
gcloud builds submit --tag gcr.io/platform-partners-des/etl-st2json

# Deploy
gcloud run jobs update etl-st2json-job \
  --image gcr.io/platform-partners-des/etl-st2json \
  --region us-east1 \
  --project platform-partners-des \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 1Gi \
  --cpu 2 \
  --max-retries 1 \
  --task-timeout 1800
```

#### Job #2 - Build & Deploy Manual
```bash
cd json2bq-job

# Build
gcloud builds submit --tag gcr.io/platform-partners-des/etl-json2bq

# Deploy
gcloud run jobs update etl-json2bq-job \
  --image gcr.io/platform-partners-des/etl-json2bq \
  --region us-east1 \
  --project platform-partners-des \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 1Gi \
  --cpu 2 \
  --max-retries 1 \
  --task-timeout 2400
```

### FunciÃ³n Orquestadora

#### Deploy (No requiere Build)
```bash
gcloud functions deploy orchestrate-etl-jobs \
  --gen2 \
  --project platform-partners-des \
  --runtime python311 \
  --trigger-http \
  --entry-point orchestrate_etl_jobs \
  --source . \
  --region us-east1 \
  --service-account etl-servicetitan@platform-partners-des.iam.gserviceaccount.com \
  --memory 4Gi \
  --timeout 3600s \
  --allow-unauthenticated
```

## ğŸ“Š Funcionalidades

### âœ… Soft Delete
- Los registros eliminados se marcan con `_etl_operation = 'DELETE'`
- No se borran fÃ­sicamente de BigQuery
- Permite auditorÃ­a completa y recuperaciÃ³n

### âœ… AuditorÃ­a Completa
- Tracking de todas las operaciones (INSERT, UPDATE, DELETE)
- Timestamp de cada sincronizaciÃ³n
- Trazabilidad completa del proceso ETL

### âœ… Procesamiento Incremental
- MERGE con detecciÃ³n automÃ¡tica de cambios
- ActualizaciÃ³n solo de registros modificados
- Eficiencia en el procesamiento

## ğŸ” Endpoints Procesados

- business-units
- job-types
- technicians
- employees
- campaigns
- activities
- timesheets

## ğŸ§ª Herramientas de Testing

### Script de Prueba ETL Completo

**`test_etl_single_company.py`** - Prueba el flujo completo (extracciÃ³n + carga) para una compaÃ±Ã­a:

```bash
# Editar COMPANY_ID y TEST_ENDPOINTS en el archivo
python test_etl_single_company.py
```

### Notebook Interactivo

**`test_etl_flow.ipynb`** - VersiÃ³n visual e interactiva:

```bash
jupyter notebook test_etl_flow.ipynb
```

**Uso:** Ideal para probar nuevos endpoints antes de implementarlos en producciÃ³n.

## ğŸ“ Estructura del Proyecto

```
etl_servicetitan/
â”œâ”€â”€ orchestrate_etl/
â”‚   â””â”€â”€ main.py                              # FunciÃ³n orquestadora
â”œâ”€â”€ st2json-job/
â”‚   â”œâ”€â”€ Dockerfile                           # ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ requirements.txt                     # Dependencias Python
â”‚   â”œâ”€â”€ servicetitan_all_st_to_json.py      # Script principal
â”‚   â”œâ”€â”€ estimates_single_company.py          # Script para estimates individual
â”‚   â””â”€â”€ build_deploy.sh                      # Script de build & deploy
â”œâ”€â”€ json2bq-job/
â”‚   â”œâ”€â”€ Dockerfile                           # ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ requirements.txt                     # Dependencias Python
â”‚   â”œâ”€â”€ servicetitan_all_json_to_bigquery.py # Script principal
â”‚   â””â”€â”€ build_deploy.sh                      # Script de build & deploy
â”œâ”€â”€ test_etl_single_company.py               # Script de prueba ETL completo
â”œâ”€â”€ test_etl_flow.ipynb                       # Notebook de prueba ETL
â””â”€â”€ README.md                                # DocumentaciÃ³n completa
```

## ğŸ› ï¸ ConfiguraciÃ³n

### Service Account
- **Nombre**: `etl-servicetitan@platform-partners-des.iam.gserviceaccount.com`
- **Permisos**: BigQuery, Cloud Run, Cloud Storage

### Proyectos
- **OrquestaciÃ³n**: `platform-partners-des`
- **Datos**: `shape-mhs-1` (cada compaÃ±Ã­a tiene su propio proyecto)

### Permisos para Cloud Functions

#### Verificar Cuenta de Servicio
```bash
gcloud iam service-accounts list --filter="email:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com"
```

#### Verificar Jobs Disponibles
```bash
gcloud run jobs list --region=us-east1
```

#### Configurar Permisos Completos
```bash
# Permisos de administrador de Cloud Run
gcloud projects add-iam-policy-binding platform-partners-des \
  --member="serviceAccount:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com" \
  --role="roles/run.admin"

# Permisos para invocar Jobs
gcloud projects add-iam-policy-binding platform-partners-des \
  --member="serviceAccount:etl-servicetitan@platform-partners-des.iam.gserviceaccount.com" \
  --role="roles/run.invoker"
```

## ğŸ“ˆ Monitoreo

### Logs de Cloud Run Jobs
```bash
# Job 1 - ExtracciÃ³n de datos
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=etl-st2json-job" --limit=50 --format="table(timestamp,severity,textPayload)"

# Job 2 - Procesamiento a BigQuery
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=etl-json2bq-job" --limit=50 --format="table(timestamp,severity,textPayload)"
```

### Logs de Cloud Function
```bash
# FunciÃ³n de orquestaciÃ³n
gcloud logging read "resource.type=cloud_function AND resource.labels.function_name=orchestrate-etl-jobs" --limit=50 --format="table(timestamp,severity,textPayload)"
```

### Monitoreo de BigQuery
- **Dataset**: `shape-mhs-1.management`
- **Tabla de logs**: `etl_logs`
- **Campos ETL**: `_etl_synced`, `_etl_operation`

## ğŸ§ª Pruebas y Scheduling

### Pruebas Manuales
```bash
# Probar la funciÃ³n de orquestaciÃ³n directamente
curl -X POST https://us-east1-platform-partners-des.cloudfunctions.net/orchestrate-etl-jobs
```

### ConfiguraciÃ³n de Scheduler
```bash
# Crear job de scheduler (cada 6 horas)
gcloud scheduler jobs create http etl-orchestration-schedule \
  --schedule="0 */6 * * *" \
  --uri="https://us-east1-platform-partners-des.cloudfunctions.net/orchestrate-etl-jobs" \
  --http-method=POST \
  --location=us-east1 \
  --oidc-service-account-email=etl-servicetitan@platform-partners-des.iam.gserviceaccount.com

# Verificar jobs de scheduler
gcloud scheduler jobs list --location=us-east1

# Ejecutar manualmente el scheduler
gcloud scheduler jobs run etl-orchestration-schedule --location=us-east1

# Verificar estado del scheduler
gcloud scheduler jobs describe etl-orchestration-schedule --location=us-east1
```

## ğŸ”§ Troubleshooting

### Error de Timeout
- **SÃ­ntoma**: "Operation did not complete within the designated timeout"
- **SoluciÃ³n**: Verificar que el timeout de la funciÃ³n sea mayor que la suma de ambos Jobs

### Campos ETL Faltantes
- **SÃ­ntoma**: Tablas sin campos `_etl_synced` o `_etl_operation`
- **SoluciÃ³n**: Ejecutar script de migraciÃ³n de esquemas

### Jobs No Ejecutados
- **SÃ­ntoma**: FunciÃ³n termina sin ejecutar Jobs
- **SoluciÃ³n**: Verificar permisos del Service Account

## ğŸ“ Notas de Desarrollo

- Los campos ETL se agregan automÃ¡ticamente a nuevas tablas
- El MERGE maneja Soft Delete para registros eliminados
- La orquestaciÃ³n es sÃ­ncrona (espera a que ambos Jobs terminen)
- Los logs estÃ¡n optimizados para facilitar el monitoreo
